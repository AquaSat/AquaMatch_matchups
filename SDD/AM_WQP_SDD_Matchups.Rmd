---
title: "AquaMatch WQP SDD Matchups"
author: "ROSSyndicate"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 80
---

```{r}
library(tidyverse) 
library(data.table)
# FYI some conflicts with data.table, mostly {dplyr} and {lubridate} 
# functions, to use the tidyverse version of these functions you will 
# need to use the `package_name::function()` (eg: `dplyr::select()`) to
# access
library(sf)
library(arrow)
library(googledrive)

drive_auth() # files sourced from Drive are available to any Google User, the console will walk through authentication steps.
```

# Purpose

This markdown file walks through the process of creating matchups from the
AquaMatch harmonized data from the Water Quality Portal for Secchi disc depth
(SDD) and the AquaMatch Landsat C2 SR data across the United States and
Territories.

## Bring in data

SDD data for AquaMatch are stored on [EDI Data
Repostiory](https://portal.edirepository.org/nis/mapbrowse?packageid=edi.1856.1).
We use the helper script generated by EDI to read in the SDD data - this is
stored in the `src` folder within the `SDD` subfolder of the matchup repository.

The citation for these data is:

De La Torre, J., B.G. Steele, M.R. Brousil, M.F. Meyer, K. Willi, and M.R. Ross.
2025. AquaMatch Secchi Disk Depth Data from Water Quality Portal: \~1970-2024
ver 1. Environmental Data Initiative.
<https://doi.org/10.6073/pasta/542a305e8484ae5abc33881bd7761308> (Accessed
2025-06-05).

```{r}
# This code chunk will take a few minutes to run if not run previously
source("SDD/src/load_EDI_WQP_SDD.R")

# at this time, the C2 data are sourced from Drive, will be updated once the pub is out
# This may take several minutes if the files have not yet been downloaded.
source("SDD/src/load_Landsat_C2_SRST.R")
```

Great. Now onto making magic.

## Making Matchups

There are many different ways and filters that can be applied to matchups. River
sites change more rapidly than lake sites (generally speaking), so matchup
windows (the time allowed between satellite acquisition and in situ
observation/measurement) should be shorter. We use data.table functions for
these applications because they are the most efficient for datasets of this
size.

The following function makes matchups based on the prescribed window.

```{r}
#' @param sat_fp: filepath to the satellite data (here, eg `LS4_fp`)
#' @param data: in situ data (here, eg ``)
#' @param window: integer of number of days on either side of the insitu measuerment
make_matchups <- function(sat_fp, data, window) {
  data <- data %>% 
    mutate(harmonized_utc = force_tz(harmonized_utc, "UTC"),
           date = ymd(format(harmonized_utc, "%Y-%m-%d")))
  sat <- read_csv(sat_fp) %>% 
    filter(siteSR_id %in% unique(data$siteSR_id))
  
  sat_less <- sat %>% 
    select(sat_data_id, rowid, calc_date) 
  
  # coerce to data.table
  setDT(data)
  setDT(sat_less)
  setDT(sat)
  
  # overjoin using data.table syntax (cause this is biiiiiiig) and also filter in one step (also because of size)
  matches <- sat_less[data, on = .(rowid), allow.cartesian = TRUE][abs(as.integer(difftime(date, calc_date, units = "days"))) <= window]
  
  # add the sat data back in
  left_join(matches, sat)
}

```

## Applying correction coefficients
